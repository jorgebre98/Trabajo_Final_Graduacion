{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be7a6ea6",
   "metadata": {},
   "source": [
    "## Tecnológico de Costa Rica\n",
    "\n",
    "### Autor: Jorge Andrés Brenes Alfaro\n",
    "\n",
    "## Red mimetizadora\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48629b1",
   "metadata": {},
   "source": [
    "## 1. Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a987f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU, TimeDistributed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8faef9",
   "metadata": {},
   "source": [
    "## 2. Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab560339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Dir = os.listdir('/Users/jorge/Documents/TEC/TFG/Datos_Recolectados')\n",
    "Data_Collect = np.array([[0,0,0,0]])\n",
    "for filename in Dir:\n",
    "    file = pd.read_csv('/Users/jorge/Documents/TEC/TFG/Datos_Recolectados/'+filename)\n",
    "    Data_Collect = np.append(Data_Collect, file.values,axis=0)\n",
    "train_data = Data_Collect[:,2]\n",
    "train_label = Data_Collect[:,3]\n",
    "\n",
    "\n",
    "train_data = np.array([])\n",
    "val_data = np.array([])\n",
    "train_label = np.array([])\n",
    "val_label = np.array([])\n",
    "cont=0\n",
    "\n",
    "while(cont < Data_Collect[:,2].shape[0]):\n",
    "    if cont < round(Data_Collect[:,2].shape[0]*0.75):\n",
    "        train_data = np.append(train_data, Data_Collect[:,2][cont])\n",
    "        train_label = np.append(train_label, Data_Collect[:,3][cont])\n",
    "    else:\n",
    "        val_data = np.append(val_data, Data_Collect[:,3][cont])\n",
    "        val_label = np.append(val_label, Data_Collect[:,3][cont])\n",
    "    cont+=1\n",
    "\n",
    "train_data = np.reshape(train_data,(1,train_data.shape[0],1))\n",
    "train_label = np.reshape(train_label,(1,train_label.shape[0],1))\n",
    "\n",
    "val_data = np.reshape(val_data,(1,val_data.shape[0],1))\n",
    "val_label = np.reshape(val_data,(1,val_label.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec47fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63423229",
   "metadata": {},
   "source": [
    "## 3. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b1923a",
   "metadata": {},
   "source": [
    "### 3.1 Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ad37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(64, input_shape=(train_data.shape[1],1),return_sequences=True))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(TimeDistributed(Dense(1)))  #there is no difference between this and model.add(Dense(1))...\n",
    "model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mse','acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59b4162",
   "metadata": {},
   "source": [
    "### 3.2 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091be107",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data, train_label,\n",
    "                    epochs=500, batch_size=8,\n",
    "                    validation_data = (val_data,val_label),\n",
    "                    verbose=2)\n",
    "\n",
    "#testPredict = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d7a11",
   "metadata": {},
   "source": [
    "### 3.3 Model Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b35b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss, accuracy = model.evaluate(testX,output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb5443",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, 'GRU_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e8fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "epochs=range(1,len(loss)+1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss,'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss,'r', label='Validation loss')\n",
    "plt.title('Training and validation losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
