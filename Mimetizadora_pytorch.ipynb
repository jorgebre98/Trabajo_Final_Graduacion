{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f092df",
   "metadata": {},
   "source": [
    "# ************************************************************* #\n",
    "#               Copyright (C) 2022 Jorge Brenes Alfaro.\n",
    "#               EL5617 Trabajo Final de Graduación.\n",
    "#               Escuela de Ingeniería Electrónica.\n",
    "#               Tecnológico de Costa Rica.\n",
    "# ************************************************************* #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdeeaf",
   "metadata": {},
   "source": [
    "### Se obtiene las versión de cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b848826",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!nvcc -V\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633d8ebc",
   "metadata": {},
   "source": [
    "## Instalación de WANDB y Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93029d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b843183",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ef219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f40a2",
   "metadata": {},
   "source": [
    "## Si se hace uso de google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a8def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "root = '/content/drive/Othercomputers/Mi portátil/TEC/TFG/Datos_Recolectados/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ef9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 100,\n",
    "    \"learning_rate\":0.001,\n",
    "    \"Dropout\": 0.35,\n",
    "    \"n_layers\":1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddce716b",
   "metadata": {},
   "source": [
    "## Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d4e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directorio de la CPU\n",
    "# root = '/Users/jorge/Documents/TEC/TFG/Datos_Recolectados/'\n",
    "\n",
    "Dir = os.listdir(root)\n",
    "pwm = np.array([])\n",
    "angle = np.array([])\n",
    "\n",
    "# Read all the .csv files and make an nx4 array\n",
    "# Next, separate the pwm value and angle in their respective arrays.\n",
    "print('******************* Process the Dataset *******************',flush=True)\n",
    "print('Recolecting Data',flush=True)\n",
    "for filename in Dir:\n",
    "    files = pd.read_csv(root + filename)\n",
    "    pwm = np.append(pwm, np.concatenate((np.zeros(100),files.values[:,2])))\n",
    "    angle = np.append(angle, np.concatenate((np.zeros(100),files.values[:,3])))\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "window = wandb.config['batch_size']\n",
    "\n",
    "#For each element of training set, we have \"window\" previous training set elements\n",
    "print('Accommodating data for the GRU network',flush=True)\n",
    "for i in range(window,pwm.shape[0]):\n",
    "    X_train.append(pwm[i-window:i])\n",
    "    Y_train.append(angle[i])\n",
    "X_train, Y_train = np.array(X_train), np.array(Y_train) # Input and output arrays\n",
    "\n",
    "# Separate the values in train, validation and test data/label\n",
    "train_data, val_data, test_data = [],[],[]\n",
    "train_label, val_label, test_label = [],[],[]\n",
    "train_lenght = int(len(X_train)*3/5)\n",
    "val_lenght = int(len(X_train)*4/5)\n",
    "\n",
    "# Use 3/5 of the total data set for training \n",
    "# and 1/5 for validation and testing.\n",
    "print('Separating data in training, validation and testing',flush=True)\n",
    "for i,j in zip(X_train[:train_lenght],Y_train[:train_lenght]):\n",
    "    train_data.append(i)\n",
    "    train_label.append(j)\n",
    "\n",
    "for i,j in zip(X_train[train_lenght:val_lenght],Y_train[train_lenght:val_lenght]):\n",
    "    val_data.append(i)\n",
    "    val_label.append(j)\n",
    "    \n",
    "for i,j in zip(X_train[val_lenght:],Y_train[val_lenght:]):\n",
    "    test_data.append(i)\n",
    "    test_label.append(j)\n",
    "    \n",
    "train_data, val_data, test_data = np.array(train_data), np.array(val_data), np.array(test_data)\n",
    "train_label, val_label, test_label = torch.from_numpy(np.array(train_label)), torch.from_numpy(np.array(val_label)), torch.from_numpy(np.array(test_label))\n",
    "\n",
    "print('Total train data is: ', len(train_data), flush=True)\n",
    "print('Total validation data is: ', len(val_data), flush=True)\n",
    "print('Total test data is: ', len(test_data), flush=True)\n",
    "\n",
    "# Reshape the arrays (n,window,1). Where n is the total amount of data in the array\n",
    "print('Reshape arrays to tensors',flush=True)\n",
    "train_data = torch.from_numpy(np.reshape(train_data,(train_data.shape[0],train_data.shape[1],1)))\n",
    "val_data = torch.from_numpy(np.reshape(val_data,(val_data.shape[0],val_data.shape[1],1)))\n",
    "test_data = torch.from_numpy(np.reshape(test_data,(test_data.shape[0],test_data.shape[1],1)))\n",
    "print('******************* Finish *******************',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a24f15",
   "metadata": {},
   "source": [
    "## Definición de tamaños"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a33779",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = train_data.shape[0]\n",
    "hidden_size = train_data.shape[1]\n",
    "num_layers = train_data.shape[2]\n",
    "output_size = train_label.shape[0]\n",
    "print(sequence_length,hidden_size,num_layers,output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f2e57d",
   "metadata": {},
   "source": [
    "# Red Neuronal Recurrente GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f22d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers, output_dim, drop_prob=0.2):\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_size\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_size, output_dim)\n",
    "        #self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.output_dim,x.size(0),self.hidden_size).to(device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        #out = self.fc(self.relu(out[:,-1]))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f33b9f8",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020a49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUNetwork(sequence_length, hidden_size, num_layers, output_size, wandb.config['Dropout']).to(device)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=wandb.config['learning_rate'])\n",
    "hystory = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1995364",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894a9c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, wandb.config[\"epochs\"] + 1):\n",
    "    y_train = model(train_data.to(device))\n",
    "    loss = loss_function(input=y_train, target=train_label)\n",
    "    loss.backward() # Backward propagation. Calculate all the gradients needed to adjust the weights.\n",
    "    optimizer.step() # Uses gradients to change weight values\n",
    "    #optimizer.zero_grad() # Don't accumulate gradients in epoch iterations.\n",
    "    \n",
    "    # Calculate the accuracy without modifying the weights of the neural network\n",
    "    with torch.no_grad():\n",
    "        y_train = model(train_data)\n",
    "        correct = (y_train == train_label).sum()\n",
    "        accuracy_train = 100*correct/float(len(test_data))\n",
    "    \n",
    "    df_temp = pd.DataFrame(data={\n",
    "        'Epoch': epoch,\n",
    "        'Loss': round(loss.item(),5),\n",
    "        'Accuracy': round(accuracy.item(),5)},index=[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
